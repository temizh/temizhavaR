}
}
library(RSelenium)
library(netstat)
library(wdman)
library(uuid)
library(DBI)
library(RSQLite)
library(temizhavaR)
#dir.create(result_dir, recursive = TRUE)
result_dir = "C:/TemizHava_result_2023"
mydb <- dbConnect(RSQLite::SQLite(), "temiz-hava.sqlite")
location_2023 <- dbReadTable(mydb, "location_2023")
# Setup Selenium with Chrome options to specify download directory
eCaps <- list(chromeOptions = list(prefs = list(
"download.default_directory" = normalizePath(result_dir),
"download.prompt_for_download" = FALSE,
"download.directory_upgrade" = TRUE,
"safebrowsing.enabled" = TRUE
)))
selenium()
selenium_object <- selenium(retcommand = T, check= F)
remote_driver <- rsDriver(browser = "chrome", chromever = "125.0.6422.78",  extraCapabilities = eCaps, verbose = F, port = free_port())
remDr <- remote_driver$client
remDr$open()
remDr$navigate("https://sim.csb.gov.tr/STN/STN_Report/StationDataDownloadNew")
for (i in 1:nrow(location_2023)) {
city_dir <- file.path(result_dir, location_2023$Sehir[i])
istasyon <- location_2023$Istasyonlar[i]
# Saatlik veriler için kontrol ve indirme işlemi
if (download_check(city_dir, istasyon, "hourly")) {
download_data(
bolge = location_2023$Bolge[i],
sehir = location_2023$Sehir[i],
istasyon = istasyon,
data_type = "hourly",
startdate = "01.01.2023",
enddate = "01.01.2024",
result_dir = result_dir
)
Sys.sleep(5)  # Gerekirse bekleme süresi ekleyin
}
# Günlük veriler için kontrol ve indirme işlemi
if (download_check(city_dir, istasyon, "daily")) {
download_data(
bolge = location_2023$Bolge[i],
sehir = location_2023$Sehir[i],
istasyon = istasyon,
data_type = "daily",
startdate = "01.01.2023",
enddate = "01.01.2024",
result_dir = result_dir
)
Sys.sleep(8)  # Gerekirse bekleme süresi ekleyin
}
}
library(RSelenium)
library(netstat)
library(wdman)
library(uuid)
library(DBI)
library(RSQLite)
library(temizhavaR)
#dir.create(result_dir, recursive = TRUE)
result_dir = "C:/TemizHava_result_2023"
mydb <- dbConnect(RSQLite::SQLite(), "temiz-hava.sqlite")
location_2023 <- dbReadTable(mydb, "location_2023")
# Setup Selenium with Chrome options to specify download directory
eCaps <- list(chromeOptions = list(prefs = list(
"download.default_directory" = normalizePath(result_dir),
"download.prompt_for_download" = FALSE,
"download.directory_upgrade" = TRUE,
"safebrowsing.enabled" = TRUE
)))
selenium()
selenium_object <- selenium(retcommand = T, check= F)
remote_driver <- rsDriver(browser = "chrome", chromever = "125.0.6422.78",  extraCapabilities = eCaps, verbose = F, port = free_port())
remDr <- remote_driver$client
remDr$open()
remDr$navigate("https://sim.csb.gov.tr/STN/STN_Report/StationDataDownloadNew")
for (i in 1:nrow(location_2023)) {
city_dir <- file.path(result_dir, location_2023$Sehir[i])
istasyon <- location_2023$Istasyonlar[i]
# Saatlik veriler için kontrol ve indirme işlemi
if (download_check(city_dir, istasyon, "hourly")) {
download_data(
bolge = location_2023$Bolge[i],
sehir = location_2023$Sehir[i],
istasyon = istasyon,
data_type = "hourly",
startdate = "01.01.2023",
enddate = "01.01.2024",
result_dir = result_dir
)
Sys.sleep(5)  # Gerekirse bekleme süresi ekleyin
}
# Günlük veriler için kontrol ve indirme işlemi
if (download_check(city_dir, istasyon, "daily")) {
download_data(
bolge = location_2023$Bolge[i],
sehir = location_2023$Sehir[i],
istasyon = istasyon,
data_type = "daily",
startdate = "01.01.2023",
enddate = "01.01.2024",
result_dir = result_dir
)
Sys.sleep(8)  # Gerekirse bekleme süresi ekleyin
}
}
library(RSelenium)
library(netstat)
library(wdman)
library(uuid)
library(DBI)
library(RSQLite)
library(temizhavaR)
#dir.create(result_dir, recursive = TRUE)
result_dir = "C:/TemizHava_result_2023"
mydb <- dbConnect(RSQLite::SQLite(), "temiz-hava.sqlite")
location_2023 <- dbReadTable(mydb, "location_2023")
# Setup Selenium with Chrome options to specify download directory
eCaps <- list(chromeOptions = list(prefs = list(
"download.default_directory" = normalizePath(result_dir),
"download.prompt_for_download" = FALSE,
"download.directory_upgrade" = TRUE,
"safebrowsing.enabled" = TRUE
)))
selenium()
selenium_object <- selenium(retcommand = T, check= F)
remote_driver <- rsDriver(browser = "chrome", chromever = "125.0.6422.78",  extraCapabilities = eCaps, verbose = F, port = free_port())
remDr <- remote_driver$client
remDr$open()
remDr$navigate("https://sim.csb.gov.tr/STN/STN_Report/StationDataDownloadNew")
for (i in 1:nrow(location_2023)) {
city_dir <- file.path(result_dir, location_2023$Sehir[i])
istasyon <- location_2023$Istasyonlar[i]
# Saatlik veriler için kontrol ve indirme işlemi
if (download_check(city_dir, istasyon, "hourly")) {
download_data(
bolge = location_2023$Bolge[i],
sehir = location_2023$Sehir[i],
istasyon = istasyon,
data_type = "hourly",
startdate = "01.01.2023",
enddate = "01.01.2024",
result_dir = result_dir
)
Sys.sleep(5)  # Gerekirse bekleme süresi ekleyin
}
# Günlük veriler için kontrol ve indirme işlemi
if (download_check(city_dir, istasyon, "daily")) {
download_data(
bolge = location_2023$Bolge[i],
sehir = location_2023$Sehir[i],
istasyon = istasyon,
data_type = "daily",
startdate = "01.01.2023",
enddate = "01.01.2024",
result_dir = result_dir
)
Sys.sleep(8)  # Gerekirse bekleme süresi ekleyin
}
}
library(temizhavaR)
library(RSelenium)
library(netstat)
library(wdman)
library(uuid)
library(DBI)
library(RSQLite)
library(temizhavaR)
#dir.create(result_dir, recursive = TRUE)
result_dir = "C:/TemizHava_result_2023"
mydb <- dbConnect(RSQLite::SQLite(), "temiz-hava.sqlite")
location_2023 <- dbReadTable(mydb, "location_2023")
# Setup Selenium with Chrome options to specify download directory
eCaps <- list(chromeOptions = list(prefs = list(
"download.default_directory" = normalizePath(result_dir),
"download.prompt_for_download" = FALSE,
"download.directory_upgrade" = TRUE,
"safebrowsing.enabled" = TRUE
)))
selenium()
selenium_object <- selenium(retcommand = T, check= F)
remote_driver <- rsDriver(browser = "chrome", chromever = "125.0.6422.78",  extraCapabilities = eCaps, verbose = F, port = free_port())
remDr <- remote_driver$client
remDr$open()
remDr$navigate("https://sim.csb.gov.tr/STN/STN_Report/StationDataDownloadNew")
for (i in 1:nrow(location_2023)) {
city_dir <- file.path(result_dir, location_2023$Sehir[i])
istasyon <- location_2023$Istasyonlar[i]
# Saatlik veriler için kontrol ve indirme işlemi
if (download_check(city_dir, istasyon, "hourly")) {
download_data(
bolge = location_2023$Bolge[i],
sehir = location_2023$Sehir[i],
istasyon = istasyon,
data_type = "hourly",
startdate = "01.01.2023",
enddate = "01.01.2024",
result_dir = result_dir
)
Sys.sleep(5)  # Gerekirse bekleme süresi ekleyin
}
# Günlük veriler için kontrol ve indirme işlemi
if (download_check(city_dir, istasyon, "daily")) {
download_data(
bolge = location_2023$Bolge[i],
sehir = location_2023$Sehir[i],
istasyon = istasyon,
data_type = "daily",
startdate = "01.01.2023",
enddate = "01.01.2024",
result_dir = result_dir
)
Sys.sleep(8)  # Gerekirse bekleme süresi ekleyin
}
}
library(temizhavaR)
library(RSelenium)
library(netstat)
library(wdman)
library(uuid)
library(DBI)
library(RSQLite)
library(temizhavaR)
#dir.create(result_dir, recursive = TRUE)
result_dir = "C:/TemizHava_result_2023"
mydb <- dbConnect(RSQLite::SQLite(), "temiz-hava.sqlite")
location_2023 <- dbReadTable(mydb, "location_2023")
eCaps <- list(chromeOptions = list(prefs = list(
"download.default_directory" = normalizePath(result_dir),
"download.prompt_for_download" = FALSE,
"download.directory_upgrade" = TRUE,
"safebrowsing.enabled" = TRUE
)))
selenium()
selenium_object <- selenium(retcommand = T, check= F)
remote_driver <- rsDriver(browser = "chrome", chromever = "125.0.6422.78",  extraCapabilities = eCaps, verbose = F, port = free_port())
remDr <- remote_driver$client
remDr$open()
remDr$navigate("https://sim.csb.gov.tr/STN/STN_Report/StationDataDownloadNew")
for (i in 1:nrow(location_2023)) {
city_dir <- file.path(result_dir, location_2023$Sehir[i])
istasyon <- location_2023$Istasyonlar[i]
# for hourly data
if (download_check(city_dir, istasyon, "hourly")) {
download_data(
bolge = location_2023$Bolge[i],
sehir = location_2023$Sehir[i],
istasyon = istasyon,
data_type = "hourly",
startdate = "01.01.2023",
enddate = "01.01.2024",
result_dir = result_dir
)
Sys.sleep(5)
}
# for daily data
if (download_check(city_dir, istasyon, "daily")) {
download_data(
bolge = location_2023$Bolge[i],
sehir = location_2023$Sehir[i],
istasyon = istasyon,
data_type = "daily",
startdate = "01.01.2023",
enddate = "01.01.2024",
result_dir = result_dir
)
Sys.sleep(8)
}
}
library(temizhavaR)
library(RSelenium)
library(netstat)
library(wdman)
library(uuid)
library(DBI)
library(RSQLite)
library(temizhavaR)
#dir.create(result_dir, recursive = TRUE)
result_dir = "C:/TemizHava_result_2023"
mydb <- dbConnect(RSQLite::SQLite(), "temiz-hava.sqlite")
location_2023 <- dbReadTable(mydb, "location_2023")
eCaps <- list(chromeOptions = list(prefs = list(
"download.default_directory" = normalizePath(result_dir),
"download.prompt_for_download" = FALSE,
"download.directory_upgrade" = TRUE,
"safebrowsing.enabled" = TRUE
)))
selenium()
selenium_object <- selenium(retcommand = T, check= F)
remote_driver <- rsDriver(browser = "chrome", chromever = "125.0.6422.78",  extraCapabilities = eCaps, verbose = F, port = free_port())
remDr <- remote_driver$client
remDr$open()
remDr$navigate("https://sim.csb.gov.tr/STN/STN_Report/StationDataDownloadNew")
for (i in 1:nrow(location_2023)) {
city_dir <- file.path(result_dir, location_2023$Sehir[i])
istasyon <- location_2023$Istasyonlar[i]
# for hourly data
if (download_check(city_dir, istasyon, "hourly")) {
download_data(
bolge = location_2023$Bolge[i],
sehir = location_2023$Sehir[i],
istasyon = istasyon,
data_type = "hourly",
startdate = "01.01.2023",
enddate = "01.01.2024",
result_dir = result_dir
)
Sys.sleep(5)
}
# for daily data
if (download_check(city_dir, istasyon, "daily")) {
download_data(
bolge = location_2023$Bolge[i],
sehir = location_2023$Sehir[i],
istasyon = istasyon,
data_type = "daily",
startdate = "01.01.2023",
enddate = "01.01.2024",
result_dir = result_dir
)
Sys.sleep(8)
}
}
remDr$close()
remote_driver$server$stop()
dbDisconnect(mydb)
list.files()
setwd()
setwd()
setwd(C:/TemizHava_raw_data_2023)
setwd("C:/TemizHava_raw_data_2023")
getwd()
setwd("C:/TemizHava_raw_data2023/")
list.files()
list.files??
list.files?
?list.files
list.files(pattern = "xlsx", recursive = TRUE)
raw_dir <- "C:/TemizHava_raw_data2023/"
source("init.TemizHava.R")
source("init.TemizHava.R")
setwd(raw_dir)
istasyon <- list.files(pattern = "xlsx", recursive = TRUE)
# istasyon <- read_excel(paste0(data_dir, "mersin-tarsus-gunluk-detay.xlsx"))
processed_data <- data_preprocessing(istasyon[1])
istasyon[1]
gunluk_istasyon <- grep("gunluk_detay", istasyon)
gunluk_istasyon
gunluk_istasyon <- istasyon[grep("gunluk_detay", istasyon)]
gunluk_istasyon
# istasyon <- read_excel(paste0(data_dir, "mersin-tarsus-gunluk-detay.xlsx"))
processed_data <- data_preprocessing(gunluk_istasyon[1])
# istasyon <- read_excel(paste0(data_dir, "mersin-tarsus-gunluk-detay.xlsx"))
processed_data <- data_preprocessing(gunluk_istasyon[1])
data
istasyonlar <- list.files(pattern = "xlsx", recursive = TRUE)
gunluk_istasyonlar <- istasyonlar[grep("gunluk_detay", istasyonlar)]
istasyonlar <- list.files(pattern = "xlsx", recursive = TRUE)
gunluk_istasyonlar <- istasyonlar[grep("gunluk_detay", istasyonlar)]
istasyon <- read_excel(gunluk_istasyon[1])
library(readxl)
istasyon <- read_excel(gunluk_istasyon[1])
View(istasyon)
processed_data <- data_preprocessing(istasyon)
processed_data <- data_preprocessing(istasyon)
library(dplyr)
processed_data <- data_preprocessing(istasyon)
View(processed_data)
library(temizhavaR)
daily_detail_save_to_database(processed_data)
View(location_2023)
library(temizhavaR)
daily_detail_save_to_database(processed_data)
dbDisconnect(mydb)
library(DBI)
library(readxl)
library(uuid)
#library(RSQLite)
# create a connection to database
mydb <- dbConnect(RSQLite::SQLite(), "temiz-hava.sqlite")
hourly_detail <- dbReadTable(mydb, "hourly_detail")
mydb_hourly_detail <- "
CREATE TABLE hourly_detail (
Istasyon TEXT,
location_id TEXT,
Tarih DATETIME,
PM10 DOUBLE,
\"PM2.5\" DOUBLE,
SO2 DOUBLE,
CO DOUBLE,
NO2 DOUBLE,
NOX DOUBLE,
NO DOUBLE,
O3 DOUBLE
);
"
dbExecute(mydb, mydb_hourly_detail)
hourly_detail <- dbReadTable(mydb, "hourly_detail")
dbDisconnect(mydb)
library(readxl)
library(dplyr)
library(lubridate)
library(RSQLite)
library(temizhavaR)
#SAVE EXCEL TO DATABASE FOR DAILY DETAIL
source("init.TemizHava.R")
getwd()
setwd("C:/TemizHava_raw_data2023/")
source("init.TemizHava.R")
setwd(raw_dir)
istasyonlar <- list.files(pattern = "xlsx", recursive = TRUE)
saatlik_istasyonlar <- istasyonlar[grep("saatlik_detay", istasyonlar)]
for (istasyon_file in saatlik_istasyonlar) {
# Read the Excel file
istasyon <- read_excel(istasyon_file)
# Process the data
processed_data <- data_preprocessing(istasyon)
# Save processed data to the database
hourly_detail_save_to_database(processed_data)
}
library(temizhavaR)
error_log <- list()
for (istasyon_file in saatlik_istasyonlar) {
tryCatch({
# Read the Excel file
istasyon <- read_excel(istasyon_file)
# Process the data using custom preprocessing function
processed_data <- data_preprocessing(istasyon)
# Save processed data to the database using custom save function
hourly_detail_save_to_database(processed_data)
cat(paste("Processed and saved:", istasyon_file, "\n"))
}, error = function(e) {
# Log the error with file name
error_log[[istasyon_file]] <- e
cat(paste("Error processing:", istasyon_file, "\n"))
})
}
# Print error log
if (length(error_log) > 0) {
cat("Errors occurred during processing:\n")
print(error_log)
}
if (length(error_log) > 0) {
cat("Errors occurred during processing:\n")
print(error_log)
}
library(DBI)
library(readxl)
library(uuid)
#library(RSQLite)
# create a connection to database
mydb <- dbConnect(RSQLite::SQLite(), "temiz-hava.sqlite")
hourly_detail <- dbReadTable(mydb, "hourly_detail")
View(hourly_detail)
dbDisconnect(mydb)
library(tidyverse)
library(readxl)
library(dplyr)
library(temizhavaR)
library(DBI)
library(readxl)
library(uuid)
library(dygraphs)
# istasyonu sqlden alamadıgında boslukları birlestir
station_name <- "Adana-Seyhan"
parameters <- c("PM10")
total_days <- 8761
parameter = "PM10"
parameter_name <- "PM10"
hourly_detail_data <- hourly_detail_load_from_database(station_name)
View(hourly_detail_data)
create_hourly_time_series_graph(hourly_detail_data, station_name, parameters)
print(paste(parameter_name,": Veri alınan istasyon listesi" ))
hourly_list_stations_with_parameter(parameter_name)
station_name <- "Mersin - Akdeniz"
parameters <- c("PM2.5")
total_days <- 365
parameter = "PM2.5"
parameter_name <- "\"PM2.5\""
city_name <- "ADANA"
daily_detail_data <- daily_detail_load_from_database(station_name)
new_pm25_from_pm10_yearly_average()
calculate_overall_average_by_city(parameter_name)
library(DBI)
library(readxl)
library(uuid)
#library(RSQLite)
# create a connection to database
mydb <- dbConnect(RSQLite::SQLite(), "temiz-hava.sqlite")
location_2023 <- dbReadTable(mydb, "location_2023")
View(location_2023)
dbDisconnect(mydb)
library(temizhavaR)
calculate_overall_average_by_city(parameter_name)
View(daily_detail_data)
library(temizhavaR)
calculate_overall_average_by_city(parameter_name)
calculate_overall_average_by_city(parameter_name)
calculate_overall_average_by_city(parameter_name)
calculate_overall_average_by_city(parameter_name)
new_pm25_from_pm10_yearly_average()
calculate_overall_average_by_city(parameter_name)
library(temizhavaR)
calculate_overall_average_by_city(parameter_name)
calculate_overall_average_by_city(parameter_name)
calculate_overall_average_by_city(parameter_name)
calculate_overall_average_by_city(parameter_name)
calculate_overall_average_by_city(parameter_name)
